{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "--------------------------------\n",
    "Autor : Lozada Sánchez Alan Omar\n",
    "Date : 02/12/2021\n",
    "--------------------------------\n",
    "Requirements :\n",
    "adjustText==0.7.3\n",
    "argon2-cffi==21.1.0\n",
    "attrs==21.2.0\n",
    "backcall==0.2.0\n",
    "bioinfokit==2.0.6\n",
    "bleach==4.1.0\n",
    "certifi==2021.10.8\n",
    "cffi==1.15.0\n",
    "charset-normalizer==2.0.7\n",
    "colorlover==0.3.0\n",
    "combat==0.3.0\n",
    "cufflinks==0.17.3\n",
    "cycler==0.11.0\n",
    "debugpy==1.5.1\n",
    "decorator==5.1.0\n",
    "defusedxml==0.7.1\n",
    "entrypoints==0.3\n",
    "GEOparse==2.0.3\n",
    "gtfparse==1.2.1\n",
    "idna==3.3\n",
    "importlib-resources==5.4.0\n",
    "ipykernel==6.5.0\n",
    "ipython==7.29.0\n",
    "ipython-genutils==0.2.0\n",
    "ipywidgets==7.6.5\n",
    "jedi==0.18.0\n",
    "Jinja2==3.0.2\n",
    "joblib==1.1.0\n",
    "jsonschema==4.2.1\n",
    "jupyter-client==7.0.6\n",
    "jupyter-core==4.9.1\n",
    "jupyterlab-pygments==0.1.2\n",
    "jupyterlab-widgets==1.0.2\n",
    "kaleido==0.2.1\n",
    "kiwisolver==1.3.2\n",
    "MarkupSafe==2.0.1\n",
    "matplotlib==3.4.3\n",
    "matplotlib-inline==0.1.3\n",
    "matplotlib-venn==0.11.6\n",
    "mistune==0.8.4\n",
    "mpmath==1.1.0\n",
    "nbclient==0.5.4\n",
    "nbconvert==6.2.0\n",
    "nbformat==5.1.3\n",
    "nest-asyncio==1.5.1\n",
    "notebook==6.4.5\n",
    "numpy==1.18.5\n",
    "packaging==21.2\n",
    "pandas==1.1.5\n",
    "pandocfilters==1.5.0\n",
    "parso==0.8.2\n",
    "patsy==0.5.1\n",
    "pexpect==4.8.0\n",
    "pickleshare==0.7.5\n",
    "Pillow==8.4.0\n",
    "plotly==5.3.1\n",
    "prometheus-client==0.12.0\n",
    "prompt-toolkit==3.0.22\n",
    "ptyprocess==0.7.0\n",
    "pycparser==2.20\n",
    "Pygments==2.10.0\n",
    "pyparsing==2.4.7\n",
    "PyPDF2==1.26.0\n",
    "pyrsistent==0.18.0\n",
    "python-dateutil==2.8.2\n",
    "pytz==2021.3\n",
    "pyzmq==22.3.0\n",
    "requests==2.26.0\n",
    "scikit-learn==1.0.1\n",
    "scipy==1.7.2\n",
    "seaborn==0.11.2\n",
    "Send2Trash==1.8.0\n",
    "six==1.16.0\n",
    "statsmodels==0.13.0\n",
    "tabulate==0.8.9\n",
    "tenacity==8.0.1\n",
    "terminado==0.12.1\n",
    "testpath==0.5.0\n",
    "textwrap3==0.9.2\n",
    "threadpoolctl==3.0.0\n",
    "tornado==6.1\n",
    "tqdm==4.62.3\n",
    "traitlets==5.1.1\n",
    "urllib3==1.26.7\n",
    "wcwidth==0.2.5\n",
    "webencodings==0.5.1\n",
    "widgetsnbextension==3.5.2\n",
    "zipp==3.6.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3647515",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c877c1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pysradb\\utils.py:14: TqdmExperimentalWarning:\n",
      "\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import io\n",
    "import cufflinks as cf\n",
    "import GEOparse\n",
    "from pysradb.sraweb import SRAweb\n",
    "from bioinfokit.analys import norm\n",
    "from gtfparse import read_gtf\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "from PyPDF2 import PdfFileMerger\n",
    "from combat.pycombat import pycombat\n",
    "import logging\n",
    "import scipy.stats as stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3774efb",
   "metadata": {},
   "source": [
    "# Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones para matplot\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "# Configuraciones para pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.min_rows', 20)\n",
    "# Configuraciones para cufflinks\n",
    "cf.go_offline()\n",
    "# Configuraciones para logging\n",
    "# (mensajes de INFO, DEBUG, WARNING, ERROR, CRITICAL)\n",
    "logger = logging.getLogger('APP')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(fmt='[%(name)s] %(asctime)s %(levelname)s - %(message)s',datefmt='%d-%m-%y %H:%M:%S')\n",
    "_handler = logging.StreamHandler()\n",
    "_handler.setLevel(logging.DEBUG)\n",
    "_handler.setFormatter(formatter)\n",
    "logger.handlers.clear() # Borra los handlers anteriores \n",
    "logger.addHandler(_handler)\n",
    "# handler para escribir los mensajes en un archivo\n",
    "# file_handler = logging.FileHandler('logs.log')\n",
    "# file_handler.setLevel(logging.DEBUG)\n",
    "# file_handler.setFormatter(formatter)\n",
    "# logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64cb7b",
   "metadata": {},
   "source": [
    "# Establecer espacio y forma de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41232daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True si se va a trabajar en Linux, false si se trabaja en Windows.\n",
    "isLinux = False\n",
    "# True si se desea ver las graficas en pantalla.\n",
    "# False si se va a ejecutar en linea de comandos (sin interfaz gráfica).\n",
    "showGraphs = True\n",
    "# Plataforma sobre la que se va a trabajar.\n",
    "platform = 'GPL19081'\n",
    "\n",
    "# Directorio de trabajo principal.\n",
    "work_dir = f'G:/Trabajos/servicioSocial/{platform}'\n",
    "os.makedirs(work_dir) if not os.path.exists(work_dir) else None # Crea la carpeta si no existe.\n",
    "os.chdir (work_dir)\n",
    "# Directorio para archivos soft (metadata).\n",
    "metadata_dir = f'{work_dir}/metadata'\n",
    "# Directorio para los experimentos (series).\n",
    "experiments_dir = f'{work_dir}/experiments'\n",
    "# Directorio para documentos (pdfs, csv).\n",
    "documents_dir = f'{work_dir}/documents'\n",
    "\n",
    "# Directorio del script de R (gene_count.R) para contar genes.\n",
    "genecount_script = f'{work_dir}/gene_count.R'\n",
    "# Directorio del archivo de referencia del genoma (.fna.gz).\n",
    "genomaref_fnafile = f'{work_dir}/GCF_000149245.1_CNA3_genomic.fna.gz'\n",
    "# Directorio del archivo de anotaciones del genoma (.gtf.gz).\n",
    "genomaannot_gtffile = f'{work_dir}/GCF_000149245.1_CNA3_genomic.gtf.gz'\n",
    "# Correo para descargas.\n",
    "correo = 'correo@gmail.com'\n",
    "\n",
    "###############################################################\n",
    "### En Linux es necesario instalar sratoolkit y R.          ###\n",
    "### En Windows se especifica la carpeta bin de sratoolkit y ###\n",
    "### el directorio donde esta instalado R.                   ###\n",
    "###############################################################\n",
    "if isLinux:\n",
    "    # Forma de ejecutar un script de R.\n",
    "    rscript_dir = 'Rscript'\n",
    "else:\n",
    "    # Directorio bin de sratoolkit.\n",
    "    sratoolkit_dir = f'{work_dir}/sratoolkit.2.11.1-win64/bin'\n",
    "    # Directorio de R (Rscript.exe) para ejecutar archivos R.\n",
    "    rscript_dir = 'C:/\"Program Files\"/R/R-4.1.1/bin/Rscript.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mensajes en pantalla de los directorios elegidos\n",
    "#-------------------------------------------------\n",
    "logger.info('Ejecución esblecida para Linux') if isLinux else logger.info('Ejecución establecida para Windows')\n",
    "logger.info(f'Plataforma {platform}')\n",
    "logger.info(f'Directorio principal {work_dir}')\n",
    "logger.info(f'Directorio para metadata {metadata_dir}')\n",
    "logger.info(f'Directorio para las series {experiments_dir}')\n",
    "logger.info(f'Directorio para documentos {documents_dir}')\n",
    "logger.info(f'Script de R para el conteo de genes {genecount_script}')\n",
    "logger.info(f'Archivo de referencia del genoma {genomaref_fnafile}')\n",
    "logger.info(f'Archivo de anotaciones del genoma {genomaannot_gtffile}')\n",
    "logger.info(f'Correo electronico {correo}')\n",
    "logger.info(f'Directorio de sratoolkit {sratoolkit_dir}') if not isLinux else None\n",
    "logger.info(f'Directorio de R {rscript_dir}') if not isLinux else None\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20542d3",
   "metadata": {},
   "source": [
    "# Descarga de metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3b38e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info(f'Descarga de metadata para la plataforma {platform}')\n",
    "# Descarga de metadata de la plataforma.\n",
    "gpl = GEOparse.get_GEO(geo = platform, destdir = metadata_dir)\n",
    "# Nombres de las series de la plataforma.\n",
    "series = dict.fromkeys(gpl.metadata['series_id'], None)\n",
    "logger.info(f'Descarga de metadata para la plataforma {platform} finalizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03fea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f'Descarga de metadata para las series de la plataforma {platform}')\n",
    "# Descarga de metadata de las series\n",
    "for serie in series.keys():\n",
    "    series[ serie ] = GEOparse.get_GEO(geo = serie, destdir = metadata_dir)\n",
    "logger.info(f'Descarga de metadata para las series de la plataforma {platform} finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070c0fc",
   "metadata": {},
   "source": [
    "# Descarga de archivos sra y transformacion a fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da528710",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isLinux: #( Windows ).\n",
    "    # Cambiar directorio principal a las herramientas de SRAToolKit.\n",
    "    os.chdir(sratoolkit_dir)\n",
    "    logger.info(f'Cambio de directorio: {sratoolkit_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04d7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Descarga con sra toolkit\n",
    "db = SRAweb()\n",
    "# Ejecutar hasta que no haya errores de descarga o se considere finalizado.\n",
    "logger.info('Descarga de archvios sra y transformacion a fastq.gz')\n",
    "tryAgain = 'si'\n",
    "while (tryAgain == 'si'):\n",
    "    errores = {}\n",
    "    countSerie = [0,len(series.keys())]\n",
    "    for serie in series.keys():\n",
    "        countSerie[0] += 1\n",
    "        print(f'{\"*\"*(len(serie)+14)}\\n****** {serie} ****** [{countSerie[0]}/{countSerie[1]}] \\n{\"*\"*(len(serie)+14)}\\n')\n",
    "        # Control de errores de descarga.\n",
    "        errores[serie] = []\n",
    "        # Filtra las muestras para que sean solo de la plataforma elegida.\n",
    "        gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "        countMuestra = [0,len(gsmsKeys)]\n",
    "        for muestra in gsmsKeys:\n",
    "            countMuestra[0] += 1\n",
    "            print(f'****** {muestra} ****** [{countMuestra[0]}/{countMuestra[1]}]')\n",
    "            path = f'{experiments_dir}/{serie}'\n",
    "            if os.path.isfile(f'{path}/{muestra}.fastq.gz'):\n",
    "                print(f'El archivo {muestra}.fastq.gz ya existe\\n')\n",
    "            else:\n",
    "                has_error = True\n",
    "                num_error = 0\n",
    "                while (has_error and num_error < 10):\n",
    "                    try:\n",
    "                        # Obtiene la metadata con los id SRR.\n",
    "                        sampleMetadata = db.sra_metadata(muestra)\n",
    "                        pathTemp = f'{experiments_dir}/{serie}/{muestra}'\n",
    "                        os.makedirs(pathTemp) if not os.path.exists(pathTemp) else None # Crea la carpeta si no existe.\n",
    "                        for srr in sampleMetadata['run_accession']:\n",
    "                            logger.info(f'Descarga iniciada: {srr}')\n",
    "                            # Descargar el archivo sra.\n",
    "                            call([ 'prefetch', '-p', '1', '-O', pathTemp, srr ], shell = True)\n",
    "                            filePath = f'{pathTemp}/{srr}.sra' # Nombre del archvivo sra descargado.\n",
    "                            shutil.move(f'{pathTemp}/{srr}/{srr}.sra', filePath) # Mover el archivo descargado a la carpeta adecuada.\n",
    "                            logger.info(f'Descarga finalizada: {srr}')\n",
    "                            # Eliminar la carpeta vacia.\n",
    "                            os.rmdir(f'{pathTemp}/{srr}')\n",
    "                            # Transformacion a fastq.gz.\n",
    "                            logger.info('Transformación a fastq.gz en proceso.')\n",
    "                            call(['fastq-dump','--outdir',pathTemp,'--gzip','--skip-technical','--readids','--read-filter','pass','--dumpbase','--split-3','--clip',filePath],shell=True) \n",
    "                            os.remove(filePath) # Borra el archvio sra despues de ser transformado a fastq.\n",
    "                            logger.info('Transformacion a fastq.gz finalizada.')\n",
    "                        fastqFiles = [f'{pathTemp}/{x}' for x in sorted(os.listdir(pathTemp))]\n",
    "                        # mover y renombrar el(los) archivo(s) fastq a su respectiva carpeta de experimento.\n",
    "                        index = 0\n",
    "                        for file in fastqFiles:\n",
    "                            if index == 0:\n",
    "                                shutil.move(file,f'{path}/{muestra}.fastq.gz')\n",
    "                                index += 1\n",
    "                            else:\n",
    "                                if (file.endswith('pass_2.fastq.gz')):\n",
    "                                    shutil.move(file,f'{path}/{muestra}{f\"_{index+1}\" if index>1 else \"\"}_paired.fastq.gz')\n",
    "                                else:\n",
    "                                    shutil.move(file,f'{path}/{muestra}_{index+1}.fastq.gz')\n",
    "                                    index += 1\n",
    "                        # Eliminar la carpeta vacia.\n",
    "                        os.rmdir(pathTemp)\n",
    "                        has_error = False\n",
    "                    except Exception as e:\n",
    "                        logger.error(f'{e}.  Intento {num_error+1}')\n",
    "                        has_error = True\n",
    "                        num_error += 1\n",
    "                if has_error:\n",
    "                    logger.error(f'Ocurrio un error de descarga para la muestra {muestra} :c')\n",
    "                    errores[serie].append(muestra)\n",
    "\n",
    "    # ERRORES.\n",
    "    for serie in errores.keys():\n",
    "        if len(errores[serie]) > 0:\n",
    "            logger.warning(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "        else:\n",
    "            logger.info(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "    # Si hay errores de descarga se pregunta si desea repetir las descargas.\n",
    "    if sum([len(errores[x]) for x in errores.keys()]) > 0:\n",
    "        tryAgain = str(input('¿Desea ejecutar nuevamente? Teclea \"Si\" o \"No\": ')).lower()\n",
    "    else:\n",
    "        tryAgain = 'no'\n",
    "logger.info('Descarga de archvios sra y transformacion a fastq.gz finalizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86688bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Descarga usando Geoparse\n",
    "# # Ejecutar hasta que no haya errores de descarga o se considere finalizado.\n",
    "# logger.info('Descarga de archvios sra y transformacion a fastq.gz')\n",
    "# tryAgain = 'si'\n",
    "# while (tryAgain == 'si'):\n",
    "#     errores = {}\n",
    "#     countSerie = [0,len(series.keys())]\n",
    "#     for serie in series.keys():\n",
    "#         countSerie[0] += 1\n",
    "#         print(f'{\"*\"*(len(serie)+14)}\\n****** {serie} ****** [{countSerie[0]}/{countSerie[1]}] \\n{\"*\"*(len(serie)+14)}\\n')\n",
    "#         # Control de errores de descarga.\n",
    "#         errores[serie] = []\n",
    "#         # Filtra las muestras para que sean solo de la plataforma elegida.\n",
    "#         gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "#         countMuestra = [0,len(gsmsKeys)]\n",
    "#         for muestra in gsmsKeys:\n",
    "#             countMuestra[0] += 1\n",
    "#             print(f'****** {muestra} ****** [{countMuestra[0]}/{countMuestra[1]}]')\n",
    "#             path = f'{experiments_dir}/{serie}'\n",
    "#             if os.path.isfile(f'{path}/{muestra}.fastq.gz'):\n",
    "#                 print(f'El archivo {muestra}.fastq.gz ya existe\\n')\n",
    "#             else:\n",
    "#                 has_error = True\n",
    "#                 num_error = 0\n",
    "#                 while (has_error and num_error < 10):\n",
    "#                     try:\n",
    "#                         fastqName = series[serie].gsms[muestra].download_SRA(email=correo,directory=path,filetype=\"fastq\",keep_sra=False) \n",
    "#                         fastqName['SRA'].sort()\n",
    "#                         # mover y renombrar el(los) archivo(s) fastq a su respectiva carpeta de experimento.\n",
    "#                         index = 0\n",
    "#                         for file in fastqName['SRA']:\n",
    "#                             if index == 0:\n",
    "#                                 shutil.move(file,f'{path}/{muestra}.fastq.gz')\n",
    "#                                 index += 1\n",
    "#                             else:\n",
    "#                                 if (file.endswith('pass_2.fastq.gz')):\n",
    "#                                     shutil.move(file,f'{path}/{muestra}{f\"_{index+1}\" if index>1 else \"\"}_paired.fastq.gz')\n",
    "#                                 else:\n",
    "#                                     shutil.move(file,f'{path}/{muestra}_{index+1}.fastq.gz')\n",
    "#                                     index += 1\n",
    "#                         # Eliminar la carpeta vacia.\n",
    "#                         if isLinux:\n",
    "#                             os.rmdir('/'.join(fastqName['SRA'][0].split('/')[:-1]))\n",
    "#                         else:\n",
    "#                             os.rmdir('/'.join(fastqName['SRA'][0].split('\\\\')[:-1]))\n",
    "#                         has_error = False\n",
    "#                     except:\n",
    "#                         logger.error(f'Intento {num_error+1}')\n",
    "#                         has_error = True\n",
    "#                         num_error += 1\n",
    "#                 if has_error:\n",
    "#                     logger.error(f'Ocurrio un error de descarga para la muestra {muestra} :c')\n",
    "#                     errores[serie].append(muestra)\n",
    "\n",
    "#     # ERRORES.\n",
    "#     for serie in errores.keys():\n",
    "#         if len(errores[serie]) > 0:\n",
    "#             logger.warning(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "#         else:\n",
    "#             logger.info(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "#     # Si hay errores de descarga se pregunta si desea repetir las descargas.\n",
    "#     if sum([len(errores[x]) for x in errores.keys()]) > 0:\n",
    "#         tryAgain = str(input('¿Desea ejecutar nuevamente? Teclea \"Si\" o \"No\": ')).lower()\n",
    "#     else:\n",
    "#         tryAgain = 'no'\n",
    "# logger.info('Descarga de archvios sra y transformacion a fastq.gz finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85b7b6",
   "metadata": {},
   "source": [
    "# Conteo de genes con ayuda de un script en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def borrarArchvivosDeEjecucionesAnteriores(path):\n",
    "    '''Borra los archivos residuales de ejecuciones anteriores del conteo de genes\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "        Dirección de la carpeta de una serie con los archvios residuales de ejecuciones de conteo de genes anteriores.  \n",
    "    Returns\n",
    "    -------\n",
    "    void\n",
    "    '''\n",
    "    if (os.path.isdir(f'{path}/bam')):\n",
    "        shutil.rmtree(f'{path}/bam')\n",
    "    if (os.path.isfile(f'{path}/rnaFeatureCount.rds')):\n",
    "        os.remove(f'{path}/rnaFeatureCount.rds')\n",
    "    if (os.path.isfile(f'{path}/rnaFeatureCount_paired.rds')):\n",
    "        os.remove(f'{path}/rnaFeatureCount_paired.rds')\n",
    "    for dire in os.listdir(path):\n",
    "        if (dire.startswith('my_index.')):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "        if (dire.endswith('_trimed.fastq.gz')):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "        if (re.fullmatch('[0-9]+\\.txt|[0-9]+-[0-9]+\\.txt',dire)):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "    logger.info(f'Carpeta {path} limpiada correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16479ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f'Conteo de genes para las muestras de cada serie de la plataforma {platform}')\n",
    "# Expresion regular para conseguir el id GEO de archivos fastq.gz.\n",
    "re_fastqfile = re.compile('(GSM[0-9]*)\\.fastq\\.gz')\n",
    "# Conteo de genes para todas las series descargadas.\n",
    "countSerie = [0, len(series.keys())]\n",
    "for serie in series.keys():\n",
    "    countSerie[0] += 1\n",
    "    print(f'{\"*\"*(len(serie)+14)}\\n****** {serie} ****** [{countSerie[0]}/{countSerie[1]}] \\n{\"*\"*(len(serie)+14)}\\n')\n",
    "    path = f'{experiments_dir}/{serie}'\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida.\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform] \n",
    "    try:\n",
    "        os.chdir(path)\n",
    "        response = 'si'\n",
    "        if (os.path.isfile(f'{path}/gene_counts.csv')):\n",
    "            print(f'Ya existe un conteo de genes para la serie {serie}')\n",
    "            response = str(input('¿Aún asi esea realizar un nuveo conteo? Teclea \"Si\" o \"No\": '))\n",
    "        inexistFastqFiles = [file for file in gsmsKeys if file not in re_fastqfile.findall(\" \".join(os.listdir(path)))]\n",
    "        if (len(inexistFastqFiles) > 0 and response.lower() == 'si'):\n",
    "            print(f'\\nEn la carpeta de la serie {serie} faltan {len(inexistFastqFiles)} archivos fastq.gz de las muestras: {\", \".join(inexistFastqFiles)}')\n",
    "            response = str(input('¿Aún asi desea continuar con el conteo de genes de las muestras existentes? Teclea \"Si\" o \"No\": '))\n",
    "        if (response.lower() == 'si'):\n",
    "            logger.info(f'Ejecutando script para la serie {serie}')\n",
    "            borrarArchvivosDeEjecucionesAnteriores(path)\n",
    "            # Crear un txt con las muestas que hay menos las que faltan.\n",
    "            with open(f'{len(gsmsKeys)}-{len(inexistFastqFiles)}.txt' if len(inexistFastqFiles)>0 else f'{len(gsmsKeys)}.txt' ,'w') as handle: \n",
    "                for sample in inexistFastqFiles:\n",
    "                    handle.write(f'{sample}\\n')\n",
    "                logger.info(f'Documento de texto con las muestras descartadas creado correctamente ({handle.name})')\n",
    "            # Ejecucion del script de R.\n",
    "            if isLinux:# Función call en linux.\n",
    "                print(call([rscript_dir,genecount_script,path,genomaref_fnafile,genomaannot_gtffile]))\n",
    "            else:\n",
    "                !{rscript_dir} {genecount_script} {path} {genomaref_fnafile} {genomaannot_gtffile}\n",
    "        else:\n",
    "            logger.info(f'Se ha cancelado el conteo de genes para la serie {serie}')\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f'No existe la carpeta {path}')\n",
    "logger.info('Conteo de genes finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6c350",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927a3fc",
   "metadata": {},
   "source": [
    "## Conteo de genes (gene_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(work_dir)\n",
    "logger.info(f'Cambio de directorio: {work_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13dd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f'INICIO. Tratamiento del conteo de genes para la plaaforma {platform}')\n",
    "# Expresión regular para filtrar los nombres de las columnas del csv generado por el script de R.\n",
    "re_GSM = re.compile('GSM[0-9]*_[0-9]*|GSM[0-9]*')\n",
    "counts = pd.DataFrame(columns=series.keys(),index=['counts','CPM','RPKM','TMP','TMM'])\n",
    "# Lectura de los archivos csv de todas las series.\n",
    "for serie in counts.keys():\n",
    "    path = f'{experiments_dir}/{serie}'\n",
    "    if os.path.isfile(f'{path}/gene_counts.csv'):\n",
    "        counts[serie]['counts'] = pd.read_csv(f'{path}/gene_counts.csv',index_col=0)\n",
    "        counts[serie]['counts'].columns = re_GSM.findall(\"\".join(counts[serie]['counts'].columns))\n",
    "        # Remplaza valores nulos con ceros.\n",
    "        counts[serie]['counts'].fillna(0,inplace=True)\n",
    "    else:\n",
    "        logger.error(f'No existe el archivio gene_counts.csv para la serie {serie}')\n",
    "logger.info('Lectura de archivos (gene_counts.csv) finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52959d",
   "metadata": {},
   "source": [
    "## Longitud de genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1dc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lectura del archivo de anotaciones del genoma (gtf).\n",
    "length_genes = read_gtf(genomaannot_gtffile)\n",
    "# Filtra solo los genes.\n",
    "length_genes = (length_genes[length_genes['feature']=='gene'])[['gene_id','start','end']]\n",
    "# Obtiene la longitud de los genes.\n",
    "length_genes['length'] = length_genes['end'] - length_genes['start']\n",
    "length_genes = length_genes.set_index('gene_id')['length']\n",
    "logger.info('Lectura de longitud de genes finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab3988",
   "metadata": {},
   "source": [
    "# Normalizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ffc28",
   "metadata": {},
   "source": [
    "## Normalización CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ba41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,serie in enumerate(counts.loc['counts'].dropna().keys()):\n",
    "    nmCPM = norm()\n",
    "    nmCPM.cpm(df = counts[serie]['counts'])\n",
    "    counts[serie]['CPM'] = nmCPM.cpm_norm\n",
    "logger.info('Normalización CPM finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36710c6",
   "metadata": {},
   "source": [
    "## Normalización RPKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    nmRPKM = norm()\n",
    "    nmRPKM.rpkm(df = counts[serie]['counts'].merge(length_genes,left_index=True,right_index=True),gl = 'length') \n",
    "    counts[serie]['RPKM'] = nmRPKM.rpkm_norm\n",
    "logger.info('Normalización RPKM finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251aa3f",
   "metadata": {},
   "source": [
    "## Normalización TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    nmTMP = norm()\n",
    "    nmTMP.tpm(df = counts[serie]['counts'].merge(length_genes,left_index=True,right_index=True),gl = 'length')\n",
    "    counts[serie]['TMP'] = nmTMP.tpm_norm\n",
    "logger.info('Normalización TMP finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52eead",
   "metadata": {},
   "source": [
    "## Normalización TMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#  edgeR TMM normalization\n",
    "#--------------------------------------\n",
    "def edger_calcnormfactors(counts_df, ref=None, logratio_trim=0.3, sum_trim=0.05, acutoff=-1e10, verbose=False):\n",
    "    # Author: Francois Aguet\n",
    "    # https://github.com/broadinstitute/pyqtl/blob/master/qtl/norm.py\n",
    "    \"\"\"\n",
    "    Calculate TMM (Trimmed Mean of M values) normalization.\n",
    "    Reproduces edgeR::calcNormFactors.default\n",
    "    Scaling factors for the library sizes that minimize\n",
    "    the log-fold changes between the samples for most genes.\n",
    "    Effective library size: TMM scaling factor * library size\n",
    "    References:\n",
    "     [1] Robinson & Oshlack, 2010\n",
    "     [2] R functions:\n",
    "          edgeR::calcNormFactors.default\n",
    "          edgeR:::.calcFactorWeighted\n",
    "          edgeR:::.calcFactorQuantile\n",
    "    \"\"\"\n",
    "\n",
    "    # discard genes with all-zero counts\n",
    "    Y = counts_df.values.copy()\n",
    "    allzero = np.sum(Y>0,axis=1)==0\n",
    "    if np.any(allzero):\n",
    "        Y = Y[~allzero,:]\n",
    "\n",
    "    # select reference sample\n",
    "    if ref is None:  # reference sample index\n",
    "        f75 = np.percentile(Y/np.sum(Y,axis=0), 75, axis=0)\n",
    "        ref = np.argmin(np.abs(f75-np.mean(f75)))\n",
    "        if verbose:\n",
    "            print('Reference sample index: '+str(ref))\n",
    "\n",
    "    N = np.sum(Y, axis=0)  # total reads in each library\n",
    "\n",
    "    # with np.errstate(divide='ignore'):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        # log fold change; Mg in [1]\n",
    "        logR = np.log2((Y/N).T / (Y[:,ref]/N[ref])).T\n",
    "        # average log relative expression; Ag in [1]\n",
    "        absE = 0.5*(np.log2(Y/N).T + np.log2(Y[:,ref]/N[ref])).T\n",
    "        v = (N-Y)/N/Y\n",
    "        v = (v.T + v[:,ref]).T  # w in [1]\n",
    "\n",
    "    ns = Y.shape[1]\n",
    "    tmm = np.zeros(ns)\n",
    "    for i in range(ns):\n",
    "        fin = np.isfinite(logR[:,i]) & np.isfinite(absE[:,i]) & (absE[:,i] > acutoff)\n",
    "        n = np.sum(fin)\n",
    "\n",
    "        loL = np.floor(n*logratio_trim)+1\n",
    "        hiL = n + 1 - loL\n",
    "        loS = np.floor(n*sum_trim)+1\n",
    "        hiS = n + 1 - loS\n",
    "        rankR = stats.rankdata(logR[fin,i])\n",
    "        rankE = stats.rankdata(absE[fin,i])\n",
    "        keep = (rankR >= loL) & (rankR <= hiL) & (rankE >= loS) & (rankE <= hiS)\n",
    "        # in [1], w erroneously defined as 1/v ?\n",
    "        tmm[i] = 2**(np.nansum(logR[fin,i][keep]/v[fin,i][keep]) / np.nansum(1/v[fin,i][keep]))\n",
    "\n",
    "    tmm = tmm / np.exp(np.mean(np.log(tmm)))\n",
    "    return tmm\n",
    "\n",
    "\n",
    "def edger_cpm_default(counts_df, lib_size=None, log=False, prior_count=0.25):\n",
    "    \"\"\"\n",
    "    edgeR normalized counts\n",
    "    Reproduces edgeR::cpm.default\n",
    "    \"\"\"\n",
    "    if lib_size is None:\n",
    "        lib_size = counts_df.sum(axis=0)\n",
    "    if log:\n",
    "        prior_count_scaled = lib_size/np.mean(lib_size) * prior_count\n",
    "        lib_size <- lib_size + 2 * prior_count_scaled\n",
    "    lib_size = 1e-6 * lib_size\n",
    "    if log:\n",
    "        return np.log2((counts_df + prior_count_scaled)/lib.size)\n",
    "    else:\n",
    "        return counts_df / lib_size\n",
    "\n",
    "\n",
    "def edger_cpm(counts_df, tmm=None, normalized_lib_sizes=True):\n",
    "    \"\"\"\n",
    "    Return edgeR normalized/rescaled CPM (counts per million)\n",
    "    Reproduces edgeR::cpm.DGEList\n",
    "    \"\"\"\n",
    "    lib_size = counts_df.sum(axis=0)\n",
    "    if normalized_lib_sizes:\n",
    "        if tmm is None:\n",
    "            tmm = edger_calcnormfactors(counts_df)\n",
    "        lib_size = lib_size * tmm\n",
    "    return counts_df / lib_size * 1e6\n",
    "#--------------------------------------\n",
    "#  edgeR TMM normalization\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ce726",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    counts[serie]['TMM'] = edger_cpm(counts_df = counts[serie]['counts'])\n",
    "logger.info('Normalización TMM finalizada')\n",
    "logger.info(f'FIN. Tratamiento del conteo de genes para la plaaforma {platform}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc12067",
   "metadata": {},
   "source": [
    "# Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxUpperWhisker( df ):\n",
    "    '''Obtener el valor maximo entre todos los brazos superiores de los boxplot generados por un data frame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor maximo entre todos los brazos superiores de los boxplot\n",
    "    '''\n",
    "    describe = df.astype('float32').describe()\n",
    "    return max(describe.loc['75%'] + (1.5*(describe.loc['75%'] - describe.loc['25%'])))\n",
    "def get_minLowerWhisker( df ):\n",
    "    '''Obtener el valor minimo entre todos los brazos inferirores de los boxplot de un data frame\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor minimo entre todos los brazos inferiores de los boxplot.\n",
    "    '''\n",
    "    describe = df.describe()\n",
    "    lowerWhisker = min(describe.loc['25%'] - (1.5*(describe.loc['75%'] - describe.loc['25%'])))\n",
    "    lowerVal = df.min().min()\n",
    "    return lowerWhisker if lowerVal < lowerWhisker else lowerVal\n",
    "\n",
    "def graficarBoxplot(df, title = 'Sin título', showfliers = False):\n",
    "    '''Gráfica los diagramas de caja y brazos de un data frame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    title : String\n",
    "        Título de la gráfica.\n",
    "    showfliers : Boolean\n",
    "        Indica si se quiere mostrar los valores atipicos de las diagrams de caja y brazos.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor minimo entre todos los brazos inferiores de los boxplot.\n",
    "    '''\n",
    "    plot = df.boxplot(column = df.columns.to_list(), return_type = 'axes',showfliers = showfliers)\n",
    "    plot.set_ylim(get_minLowerWhisker(df),get_maxUpperWhisker(df))\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_title( title )\n",
    "    plot.tick_params(axis = 'y', colors = '0.9') # 0.9 light gray\n",
    "    plot.tick_params(axis = 'x', colors = 'none')\n",
    "    plot.title.set_color('0.9')\n",
    "    plot.xaxis.grid()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fe13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    logger.info('Visualización de boxplots')\n",
    "    if (counts.isna().sum().sum() > 0):\n",
    "        logger.warning(f'Las series {\", \".join([x for x in counts.columns if counts[x].isna().sum() > 0])} no tienen una grafica asignada.') \n",
    "    countSerie = [0, len(counts.dropna(axis=1).columns)]\n",
    "    for serie in counts.dropna(axis=1).columns:\n",
    "        countSerie[0] += 1\n",
    "        print(f'****** {serie} ****** [{countSerie[0]}/{countSerie[1]}]')\n",
    "        graficarBoxplot(counts[serie]['counts'], title=f'Conteo de genes {serie}')\n",
    "        graficarBoxplot(counts[serie]['CPM'], title=f'Normalización CPM {serie}')\n",
    "        graficarBoxplot(counts[serie]['RPKM'], title=f'Normalización RPKM {serie}')\n",
    "        graficarBoxplot(counts[serie]['TMP'], title=f'Normalización TMP {serie}')\n",
    "        graficarBoxplot(counts[serie]['TMM'], title=f'Normalización TMM {serie}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffb103",
   "metadata": {},
   "source": [
    "# Creación de documentos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc46b5",
   "metadata": {},
   "source": [
    "## Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('INICIO. Creación de documentos')\n",
    "os.makedirs(documents_dir) if not os.path.exists(documents_dir) else None # Crea la carpeta si no existe\n",
    "os.chdir(documents_dir)\n",
    "logger.info(f'Cambio de directorio {documents_dir}')\n",
    "def get_bytesPdfBoxplotImage(serie, kind, boxpoints, df):\n",
    "    '''Crea un pdf en bytes con la imagen del diagrama de caja y brazos de un DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    serie : String\n",
    "        Nombre de la serie (experimento).\n",
    "    kind : String\n",
    "        Tipo de datos (counts, CPM, RPKM, TMP, TMM).\n",
    "    boxpoints : Boolean\n",
    "        Indica si se quieren mostrar los valores atipicos de los diagramas de caja y brazos.\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con: columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Bytes\n",
    "        Pdf en bytes de la imagen del boxplot.\n",
    "    '''\n",
    "    df = df.astype('float32')\n",
    "    title = f'Conteo de genes {serie}' if kind == 'counts' else f'Normalización {kind} {serie}'\n",
    "    fig = df.iplot(kind='box',boxpoints=boxpoints,title=title,yrange=[0,get_maxUpperWhisker(df)],asFigure=True) \n",
    "    fig.update_traces(marker_opacity = 0.5, selector=dict(type='box'))\n",
    "    fig.update_traces(marker_size = 2, selector=dict(type='box'))\n",
    "    fig.update_layout(showlegend = False)\n",
    "    fig.update_layout(font_size = 10)\n",
    "    fig.update_layout(width = (700 + len(df.columns)) if len(df.columns)>100 else 700)\n",
    "    fig.update_layout(height = 450)\n",
    "    return fig.to_image(format = 'pdf')\n",
    "\n",
    "def generatePdf(serie, boxpoints = False, df = counts):\n",
    "    '''Genera un archivo pdf con todas las gráficas de una serie\n",
    "    Parameters\n",
    "    ----------\n",
    "    serie : String\n",
    "        Nombre de la serie (experimento).\n",
    "    boxpoints : Boolean\n",
    "        Indica si se quieren mostrar los valores atipicos de los diagramas de caja y brazos.\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con: columnas-series, filas-kind(counts, CPM, RPKM, TMP, TMM), values-DataFrame.\n",
    "    Returns\n",
    "    -------\n",
    "    Void\n",
    "    '''\n",
    "    # Juntar los plotly en un pdf\n",
    "    merger = PdfFileMerger()\n",
    "    for kind in df.index:\n",
    "        merger.append(io.BytesIO(get_bytesPdfBoxplotImage(serie,kind,boxpoints,df[serie][kind])))\n",
    "    with open(f'{serie}.pdf','wb') as handle:\n",
    "        merger.write(handle) \n",
    "    logger.info(f'PDF generado correctamente: {serie}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (counts.isna().sum().sum() > 0):\n",
    "    logger.warning(f'Las series {\", \".join([x for x in counts.columns if counts[x].isna().sum() > 0])} no tienen datos asignados.') \n",
    "countSerie = [0, len(counts.dropna(axis=1).columns)]\n",
    "for serie in counts.dropna(axis = 1).columns:\n",
    "    countSerie[0] += 1\n",
    "    logger.info(f'{serie}  [{countSerie[0]}/{countSerie[1]}]')\n",
    "    generatePdf(serie,'outliers',counts)\n",
    "logger.info('Pdfs de boxplots generados correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c156af45",
   "metadata": {},
   "source": [
    "## Metadata de las series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b18c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.DataFrame([],columns=['geo_accession','title','summary','status','submission_date','last_update_date','type','overall_design','contributor','contact_email','contact_institute','contact_laboratory','contact_country','platform_id','total_samples','num_samples_discarded','samples_discarded']) \n",
    "# Solo guarda las series que fueron procesadas\n",
    "for serie in counts.dropna(axis=1).columns:\n",
    "    newRow = {}\n",
    "    for title in [x for x in df_metadata.columns.to_list() if x not in ['total_samples','num_samples_discarded','samples_discarded']]:\n",
    "        try:\n",
    "            newRow[title] = ', '.join(series[serie].metadata[title]) if title != 'contributor' else ', '.join(list(map(lambda x: str(x).replace(',',' '),series[serie].metadata[title])))\n",
    "        except:\n",
    "            newRow[title] = None\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "    newRow[\"total_samples\"] = len(gsmsKeys)\n",
    "    newRow[\"num_samples_discarded\"] = None\n",
    "    newRow[\"samples_discarded\"] = None\n",
    "    newRow[\"platform_id\"] = platform\n",
    "\n",
    "    # Registro de muestras descartadas\n",
    "    discarded = [x for x in gsmsKeys if x not in counts[serie]['counts'].columns]\n",
    "    if len(discarded) == 0:\n",
    "        newRow[\"num_samples_discarded\"] = 0\n",
    "        newRow[\"samples_discarded\"] = 'No samples were discarded'\n",
    "    else:\n",
    "        newRow[\"num_samples_discarded\"] = len(discarded)\n",
    "        newRow[\"samples_discarded\"] = ', '.join(discarded)\n",
    "\n",
    "    df_metadata = df_metadata.append(newRow, ignore_index=True)\n",
    "    \n",
    "df_metadata.set_index('geo_accession',inplace=True)\n",
    "df_metadata.to_csv(f'{documents_dir}/experiments_data-{platform}.csv')\n",
    "logger.info(f'Metadata de series generado correctamente en: {documents_dir}/experiments_data-{platform}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c521a",
   "metadata": {},
   "source": [
    "## Metadata de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84684e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metadataSample = pd.DataFrame([],columns=['geo_accession','title','organism_ch1','status','submission_date','last_update_date','growth_protocol_ch1','molecule_ch1','extract_protocol_ch1','data_processing','data_processing','instrument_model','library_selection','library_source','library_strategy','platform_id']) \n",
    "# Solo guarda las series que fueron procesadas\n",
    "for serie in counts.dropna(axis=1).columns:\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "    # Registro de muestras descartadas\n",
    "    discarded = [x for x in gsmsKeys if x not in counts[serie]['counts'].columns]\n",
    "    for muestra in [x for x in gsmsKeys if x not in discarded]: # Si hay muestras descartadas no se añaden a este archivo\n",
    "        newRow = {}\n",
    "        for title in df_metadataSample.columns:\n",
    "            try:\n",
    "                newRow[title] = f'\\n'.join(series[serie].gsms[muestra].metadata[title])\n",
    "            except:\n",
    "                newRow[title] = None\n",
    "\n",
    "        df_metadataSample = df_metadataSample.append(newRow, ignore_index=True)\n",
    "    \n",
    "df_metadataSample.set_index('geo_accession',inplace=True)\n",
    "df_metadataSample.to_csv(f'{documents_dir}/samples_data-{platform}.csv')\n",
    "logger.info(f'Documento generado correctamente en: {documents_dir}/samples_data-{platform}.csv')\n",
    "logger.info('FIN. Creación de documentos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b29ba",
   "metadata": {},
   "source": [
    "# Creación de la matriz de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fcafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info('INICIO. Creación de matrices de las muestras')\n",
    "genes_id = read_gtf(genomaannot_gtffile) \n",
    "genes_id = genes_id[genes_id['feature']=='gene'].reset_index()['gene_id']\n",
    "logger.info(f'Lectura de genes del archivo {genomaannot_gtffile} finalizado')\n",
    "samples = pd.DataFrame(columns=['beforeBatchN','afterBatchN'],index=['CPM','RPKM','TMP','TMM'])\n",
    "for kind in samples.index:\n",
    "    logger.info(f'Inicio. Normalización de batch a {kind}')\n",
    "    batchVector = []\n",
    "    temp = pd.DataFrame(index=genes_id)\n",
    "    for index,serie in enumerate(counts.dropna(axis = 1).columns):\n",
    "        temp = temp.merge(counts[serie][kind],left_index=True,right_index=True,how='left').fillna(0)\n",
    "        batchVector += [index for x in range(len(counts[serie][kind].columns))] \n",
    "        \n",
    "    #### REMOVER LOS GENES QUE TENGAN VARIANZA IGUAL A CERO\n",
    "    drpgen = pd.DataFrame([],columns = temp.columns)\n",
    "    for gen in temp.index:\n",
    "        if temp.loc[gen].var() == 0:\n",
    "            drpgen = drpgen.append(temp.loc[gen])\n",
    "            temp = temp.drop([gen],axis=0)\n",
    "    logger.info(f'{len(drpgen.index)} genes tienen varianza igual a cero')\n",
    "    \n",
    "    samples['beforeBatchN'][kind] = temp.append(drpgen).astype('float32')\n",
    "    # Normalizacion de batch\n",
    "    try:\n",
    "        samples['afterBatchN'][kind] = pycombat(temp.astype('float32'),batchVector).append(drpgen).astype('float32')\n",
    "        logger.info(f'Normalización de Batch aplicada correctamente a {kind}')\n",
    "    except:\n",
    "        samples['afterBatchN'][kind] = np.NaN\n",
    "        logger.error(f'Ocurrio un problema en la normalización de batch de {kind}')\n",
    "logger.info('FIN. Creación de matrices de las muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ed8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    logger.info('Visualización de boxplots')\n",
    "    plt.rcParams[\"figure.figsize\"] = (30,15)\n",
    "    for y in samples.index:\n",
    "        for x in samples.columns:\n",
    "            print(f'{x} tipo {y}')\n",
    "            graficarBoxplot(samples[x][y],title=f'{x} tipo {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera archivos csv para cada uno de las matrices (CPM, RPKM, TMP, TMM) a las que se le aplico correctamente el ajuste de batch \n",
    "for kind in samples.dropna(axis = 0).index:\n",
    "    samples['afterBatchN'][kind].to_csv(f'{documents_dir}/matrizAfterBatch{kind}.csv')\n",
    "    logger.info(f'Matriz guardada en: {documents_dir}/matrizAfterBatch{kind}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
