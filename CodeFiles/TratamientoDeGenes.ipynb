{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------------------------------------------\n",
    "Autor Versión 1 : Lozada Sánchez Alan Omar\n",
    "\n",
    "Actualización a Versión 2: López García Juan Ángel\n",
    "                           Morales Mendoza Fernando\n",
    "                           \n",
    "Date : 01/05/2022\n",
    "-----------------------------------------------------\n",
    "Requirements :\n",
    "PYHTON 3.8.X ó 3.9.X\n",
    "R 4.1.3 ó 4.2.0\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3647515",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si alguno no está instalado utilizar el comando (en cualquier terminal): pip install nombre_paquete \n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import re\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import io\n",
    "import cufflinks as cf\n",
    "import GEOparse\n",
    "from pysradb.sraweb import SRAweb\n",
    "from bioinfokit.analys import norm\n",
    "from gtfparse import read_gtf\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "from PyPDF2 import PdfFileMerger\n",
    "import logging\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "'''\n",
    "Si al instalar combat se genera un error porque intenta reinstalar pandas, numpy o alguna otra biblioteca, \n",
    "ignorar el error y reintentar instalación hasta que no se generen errores.\n",
    "'''\n",
    "from combat.pycombat import pycombat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3774efb",
   "metadata": {},
   "source": [
    "# Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones para matplot\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "# Configuraciones para pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.min_rows', 20)\n",
    "\n",
    "# Configuraciones para cufflinks\n",
    "cf.go_offline()\n",
    "\n",
    "# Configuraciones para logging\n",
    "# (mensajes de INFO, DEBUG, WARNING, ERROR, CRITICAL)\n",
    "logger = logging.getLogger()\n",
    "handlers = logging.getLogger().handlers\n",
    "for h in handlers:\n",
    "    if isinstance(h, logging.StreamHandler):\n",
    "        handler_console = h\n",
    "        break\n",
    "    \n",
    "if handler_console is None:\n",
    "    handler_console = logging.StreamHandler()\n",
    "    \n",
    "if handler_console is not None:\n",
    "    logging.getLogger().removeHandler(handler_console)\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s %(levelname)s - %(message)s',datefmt='%d-%m-%y %H:%M:%S')    \n",
    "    handler_console.setFormatter(formatter)\n",
    "    logger.addHandler(handler_console)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64cb7b",
   "metadata": {},
   "source": [
    "# Establecer espacio y forma de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41232daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True si se va a trabajar en Linux, false si se trabaja en Windows.\n",
    "isLinux = False\n",
    "# True si se desea ver las graficas en pantalla.\n",
    "# False si se va a ejecutar en linea de comandos (sin interfaz gráfica).\n",
    "showGraphs = True\n",
    "\n",
    "# Plataforma sobre la que se va a trabajar.\n",
    "platform = 'GPL17225'\n",
    "\n",
    "# Directorio de trabajo principal (Modificar según el usuario desee)\n",
    "work_dir = f'D:/LabRedesBiologicas/Schizosaccharomyces_pombe/{platform}' \n",
    "os.makedirs(work_dir) if not os.path.exists(work_dir) else None # Crea la carpeta si no existe.\n",
    "os.chdir (work_dir)\n",
    "\n",
    "# Directorio para archivos soft (metadata).\n",
    "metadata_dir = f'{work_dir}/metadata'\n",
    "os.makedirs(metadata_dir) if not os.path.exists(metadata_dir) else None # Crea la carpeta si no existe\n",
    "# Directorio para los experimentos (series).\n",
    "experiments_dir = f'{work_dir}/experiments'\n",
    "os.makedirs(experiments_dir) if not os.path.exists(experiments_dir) else None # Crea la carpeta si no existe\n",
    "# Directorio para documentos (pdfs, csv).\n",
    "documents_dir = f'{work_dir}/documents' \n",
    "os.makedirs(documents_dir) if not os.path.exists(documents_dir) else None # Crea la carpeta si no existe\n",
    "\n",
    "    # Modificar según el usuario desee\n",
    "# Directorio del script de R (gene_count.R) para contar genes.\n",
    "genecount_script = 'D:/LabRedesBiologicas/Code/gene_count.R'\n",
    "# Directorio del archivo de referencia del genoma (.fna.gz).\n",
    "genomaref_fnafile = 'D:/LabRedesBiologicas/Schizosaccharomyces_pombe/GCF_000002945.1_ASM294v2_genomic.fna.gz'\n",
    "# Directorio del archivo de anotaciones del genoma (.gtf.gz).\n",
    "genomaannot_gtffile = 'D:/LabRedesBiologicas/Schizosaccharomyces_pombe/GCF_000002945.1_ASM294v2_genomic.gtf.gz'\n",
    "\n",
    "    # Modificar según sea el SO del usuario \n",
    "if isLinux:\n",
    "    # Directorio configurado en SRA Toolkit para almacenamiento de archivos Prefetch\n",
    "    tempSRA = ''\n",
    "    \n",
    "    # Forma de ejecutar un script de R. NO MODIFICAR\n",
    "    rscript_dir = 'Rscript'\n",
    "else:\n",
    "    # Directorio bin de sratoolkit para funciones de SRA Toolkit.\n",
    "    sratoolkit_dir = 'D:/LabRedesBiologicas/Code/sratoolkit.3.0.0-win64/bin'\n",
    "    \n",
    "    # Directorio configurado en SRA Toolkit para almacenamiento de archivos Prefetch\n",
    "    tempSRA = 'D:/LabRedesBiologicas/Code/sratoolkit.3.0.0-win64/temp/sra'\n",
    "    \n",
    "    # Directorio de R (Rscript.exe) para ejecutar archivos R.\n",
    "    rscript_dir = 'C:/R-4.1.3/bin/Rscript.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mensajes en pantalla de los directorios elegidos\n",
    "#-------------------------------------------------\n",
    "logger.info('Ejecución esblecida para Linux') if isLinux else logger.info('Ejecución establecida para Windows')\n",
    "logger.info(f'Plataforma {platform}')\n",
    "logger.info(f'Directorio principal {work_dir}')\n",
    "logger.info(f'Directorio para metadata {metadata_dir}')\n",
    "logger.info(f'Directorio para las series {experiments_dir}')\n",
    "logger.info(f'Directorio para documentos {documents_dir}')\n",
    "logger.info(f'Script de R para el conteo de genes {genecount_script}')\n",
    "logger.info(f'Archivo de referencia del genoma {genomaref_fnafile}')\n",
    "logger.info(f'Archivo de anotaciones del genoma {genomaannot_gtffile}')\n",
    "logger.info(f'Directorio de sratoolkit {sratoolkit_dir}') if not isLinux else None\n",
    "logger.info(f'Directorio de R {rscript_dir}') if not isLinux else None\n",
    "#-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20542d3",
   "metadata": {},
   "source": [
    "# Descarga de metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3b38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f'Descarga de metadata para la plataforma {platform}')\n",
    "# Descarga de metadata de la plataforma.\n",
    "gpl = GEOparse.get_GEO(geo = platform, destdir = metadata_dir)\n",
    "# Nombres de las series de la plataforma.\n",
    "series = dict.fromkeys(gpl.metadata['series_id'], None)\n",
    "logger.info(f'Descarga de metadata para la plataforma {platform} finalizada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Descarga de metadata para las series de la plataforma {platform}')\n",
    "# Descarga de metadata de las series\n",
    "for serie in series.keys():\n",
    "    series[ serie ] = GEOparse.get_GEO(geo = serie, destdir = metadata_dir)\n",
    "logger.info(f'Descarga de metadata para las series de la plataforma {platform} finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae45049",
   "metadata": {},
   "source": [
    "# Minado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04d7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not isLinux: #( Windows ).\n",
    "    # Cambiar directorio principal a las herramientas de SRAToolKit.\n",
    "    os.chdir(sratoolkit_dir)\n",
    "    logger.info(f'Cambio de directorio: {sratoolkit_dir}')\n",
    "\n",
    "# Descarga con sra toolkit\n",
    "db = SRAweb()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "#Si se genera el siguiente error: \n",
    "# \"UnboundLocalError: local variable 'exp_platform_model' referenced before assigment\n",
    "# Revisar la siguiente página y corregir el código a mano\n",
    "# -> https://github.com/saketkc/pysradb/commit/efeca93a520672351aae10578d23b0674cdf820a\n",
    "# o recuperar la biblioteca pysradb desde su fuente origanl con -> pip install git+https:://github.com/saketkc/pysradb\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Ejecutar hasta que no haya errores de descarga o se considere finalizado.\n",
    "logger.info('Descarga de archvios sra y transformacion a fastq.gz')\n",
    "tryAgain = 'si'\n",
    "while (tryAgain == 'si'):\n",
    "    errores = {}\n",
    "    countSerie = [0,len(series.keys())]\n",
    "    #Se recomienda decargar serie por serie o conjunto pequeños para evitar problemas con el espacio\n",
    "    for serie in ['GSE#####']: #series.keys():\n",
    "        countSerie[0] += 1\n",
    "        print(f'{\"*\"*(len(serie)+14)}\\n****** {serie} ****** [{countSerie[0]}/{countSerie[1]}] \\n{\"*\"*(len(serie)+14)}\\n')\n",
    "        # Control de errores de descarga.\n",
    "        errores[serie] = []\n",
    "        # Filtra las muestras para que sean solo de la plataforma elegida.\n",
    "        gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "        countMuestra = [0,len(gsmsKeys)]\n",
    "        for muestra in ['GSM#######']: #gsmsKeys:\n",
    "            countMuestra[0] += 1\n",
    "            print(f'****** {muestra} ****** [{countMuestra[0]}/{countMuestra[1]}]')\n",
    "            path = f'{experiments_dir}/{serie}'\n",
    "            if os.path.isfile(f'{path}/{muestra}.fastq.gz'):\n",
    "                print(f'El archivo {muestra}.fastq.gz ya existe\\n')\n",
    "            else:\n",
    "                has_error = True\n",
    "                num_error = 0\n",
    "                while (has_error and num_error < 10):\n",
    "                    try:\n",
    "                        # Obtiene la metadata con los id SRR.\n",
    "                        sampleMetadata = db.sra_metadata(muestra)\n",
    "                        pathTemp = f'{experiments_dir}/{serie}/{muestra}'\n",
    "                        os.makedirs(pathTemp) if not os.path.exists(pathTemp) else None # Crea la carpeta si no existe.\n",
    "                        for srr in sampleMetadata['run_accession']:\n",
    "                    \n",
    "                            # Descargar el archivo sra.\n",
    "                            logger.info(f'Descarga sra: {srr}')\n",
    "                            call(['prefetch','-p', srr], shell = True)\n",
    "                            logger.info(f'Descarga finalizada: {srr}')\n",
    "                            \n",
    "                            # Transformacion a fastq\n",
    "                            logger.info('Transformación a fastq iniciada.')\n",
    "                            call(['fasterq-dump',srr,'-p','-O',pathTemp],shell=True)\n",
    "                            logger.info('Transformacion a fastq finalizada.')\n",
    "                            \n",
    "                        \n",
    "                        # Compresión gzip y renombre de archivos fastq\n",
    "                        logger.info('Compresión gz iniciada.')\n",
    "                        fastqFiles = [f'{pathTemp}/{x}' for x in sorted(os.listdir(pathTemp))]\n",
    "                        index = 0\n",
    "                        \n",
    "                        # En caso de NO necesitar un nivel de compresión tan alto, se debe modificar la función\n",
    "                        # gzip.open('file','mode',N) agregando el parametro N\n",
    "                        # N es un entero entre 0 y 9, dónde:\n",
    "                        # N=0 -> no compresión\n",
    "                        # N=1 -> menor compresión pero más rapida\n",
    "                        # N=9 -> mayor compresión pero más lenta\n",
    "                        # por defecto se tiene un valor de N=9\n",
    "                        for file in fastqFiles:\n",
    "                            logger.info(f'Archivo {file} comprimiendose...')\n",
    "                            if index == 0:\n",
    "                                with open(file, 'rb') as f_in:\n",
    "                                    with gzip.open(f'{path}/{muestra}.fastq.gz', 'wb', 1) as f_out:\n",
    "                                        shutil.copyfileobj(f_in, f_out)\n",
    "                                index += 1\n",
    "                            else:\n",
    "                                if (file.endswith('_2.fastq')):\n",
    "                                    with open(file, 'rb') as f_in:\n",
    "                                        with gzip.open(f'{path}/{muestra}{f\"_{index}\" if index>1 else \"\"}_paired.fastq.gz', 'wb', 1) as f_out:\n",
    "                                            shutil.copyfileobj(f_in, f_out)\n",
    "                                else:\n",
    "                                    index += 1\n",
    "                                    with open(file, 'rb') as f_in:\n",
    "                                        with gzip.open(f'{path}/{muestra}_{index}.fastq.gz', 'wb', 1) as f_out:\n",
    "                                            shutil.copyfileobj(f_in, f_out)\n",
    "                        logger.info('Compresión gz finalizada.')            \n",
    "                        \n",
    "                        #Eliminando carpetas de archivos innecesarios\n",
    "                        shutil.rmtree(tempSRA)\n",
    "                        shutil.rmtree(pathTemp)\n",
    "                        \n",
    "                        has_error = False\n",
    "                    except Exception as e:\n",
    "                        logger.error(f'{e}.  Intento {num_error+1}')\n",
    "                        has_error = True\n",
    "                        num_error += 1\n",
    "                if has_error:\n",
    "                    logger.error(f'Ocurrio un error de descarga para la muestra {muestra} :c')\n",
    "                    errores[serie].append(muestra)\n",
    "\n",
    "    # ERRORES.\n",
    "    for serie in errores.keys():\n",
    "        if len(errores[serie]) > 0:\n",
    "            logger.warning(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "        else:\n",
    "            logger.info(f'La serie {serie} tuvo {len(errores[serie])} errores: {errores[serie]}')\n",
    "    # Si hay errores de descarga se pregunta si desea repetir las descargas.\n",
    "    if sum([len(errores[x]) for x in errores.keys()]) > 0:\n",
    "        tryAgain = str(input('¿Desea ejecutar nuevamente? Teclea \"Si\" o \"No\": ')).lower()\n",
    "    else:\n",
    "        tryAgain = 'no'\n",
    "logger.info('Descarga de archvios sra y transformacion a fastq.gz finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85b7b6",
   "metadata": {},
   "source": [
    "# Conteo de genes con R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def borrarArchvivosDeEjecucionesAnteriores(path):\n",
    "    '''Borra los archivos residuales de ejecuciones anteriores del conteo de genes\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "        Dirección de la carpeta de una serie con los archvios residuales de ejecuciones de conteo de genes anteriores.  \n",
    "    Returns\n",
    "    -------\n",
    "    void\n",
    "    '''\n",
    "    if (os.path.isdir(f'{path}/bam')):\n",
    "        shutil.rmtree(f'{path}/bam')\n",
    "    if (os.path.isfile(f'{path}/rnaFeatureCount.rds')):\n",
    "        os.remove(f'{path}/rnaFeatureCount.rds')\n",
    "    if (os.path.isfile(f'{path}/rnaFeatureCount_paired.rds')):\n",
    "        os.remove(f'{path}/rnaFeatureCount_paired.rds')\n",
    "    for dire in os.listdir(path):\n",
    "        if (dire.startswith('my_index.')):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "        if (dire.endswith('_trimed.fastq.gz')):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "        if (re.fullmatch('[0-9]+\\.txt|[0-9]+-[0-9]+\\.txt',dire)):\n",
    "            os.remove(f'{path}/{dire}')\n",
    "    logger.info(f'Carpeta {path} limpiada correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16479ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Conteo de genes para las muestras de cada serie de la plataforma {platform}')\n",
    "# Expresion regular para conseguir el id GEO de archivos fastq.gz.\n",
    "re_fastqfile = re.compile('(GSM[0-9]*)\\.fastq\\.gz')\n",
    "# Conteo de genes para todas las series descargadas.\n",
    "countSerie = [0, len(series.keys())]\n",
    "for serie in ['GSE#####']: #series.keys():\n",
    "    countSerie[0] += 1\n",
    "    print(f'{\"*\"*(len(serie)+14)}\\n****** {serie} ****** [{countSerie[0]}/{countSerie[1]}] \\n{\"*\"*(len(serie)+14)}\\n')\n",
    "    path = f'{experiments_dir}/{serie}'\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida.\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform] \n",
    "    try:\n",
    "        os.chdir(path)\n",
    "        response = 'si'\n",
    "        if (os.path.isfile(f'{path}/gene_counts.csv')):\n",
    "            print(f'Ya existe un conteo de genes para la serie {serie}')\n",
    "            response = str(input('¿Aún asi esea realizar un nuevo conteo? Teclea \"Si\" o \"No\": '))\n",
    "        inexistFastqFiles = [file for file in gsmsKeys if file not in re_fastqfile.findall(\" \".join(os.listdir(path)))]\n",
    "        if (len(inexistFastqFiles) > 0 and response.lower() == 'si'):\n",
    "            print(f'\\nEn la carpeta de la serie {serie} faltan {len(inexistFastqFiles)} archivos fastq.gz de las muestras: {\", \".join(inexistFastqFiles)}')\n",
    "            response = str(input('¿Aún asi desea continuar con el conteo de genes de las muestras existentes? Teclea \"Si\" o \"No\": '))\n",
    "        if (response.lower() == 'si'):\n",
    "            logger.info(f'Ejecutando script para la serie {serie}')\n",
    "            borrarArchvivosDeEjecucionesAnteriores(path)\n",
    "            # Crear un txt con las muestas que hay menos las que faltan.\n",
    "            with open(f'{len(gsmsKeys)}-{len(inexistFastqFiles)}.txt' if len(inexistFastqFiles)>0 else f'{len(gsmsKeys)}.txt' ,'w') as handle: \n",
    "                for sample in inexistFastqFiles:\n",
    "                    handle.write(f'{sample}\\n')\n",
    "                logger.info(f'Documento de texto con las muestras descartadas creado correctamente ({handle.name})')\n",
    "            # Ejecucion del script de R.\n",
    "            if isLinux: #Ejecución en Linux\n",
    "                print(call([rscript_dir,genecount_script,path,genomaref_fnafile,genomaannot_gtffile]))\n",
    "            else: #Ejecución en Windows\n",
    "                process = subprocess.Popen(f'{rscript_dir} {genecount_script} {path} {genomaref_fnafile} {genomaannot_gtffile}', shell = True,bufsize = 1, stdout=subprocess.PIPE, stderr = subprocess.STDOUT,encoding='utf-8', errors = 'replace' ) \n",
    "                while True: #Muestra progreso de ejecución del Script en tiempo real\n",
    "                    realtime_output = process.stdout.readline()\n",
    "                    if realtime_output == '' and process.poll() is not None:\n",
    "                        break\n",
    "                    if realtime_output:\n",
    "                        print(realtime_output.strip(), flush=False)\n",
    "                        sys.stdout.flush()\n",
    "        else:\n",
    "            logger.info(f'Se ha cancelado el conteo de genes para la serie {serie}')\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f'No existe la carpeta {path}')\n",
    "logger.info('Conteo de genes finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6c350",
   "metadata": {},
   "source": [
    "# Etapa Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927a3fc",
   "metadata": {},
   "source": [
    "## Conteo de genes (gene_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(work_dir)\n",
    "logger.info(f'Cambio de directorio: {work_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13dd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f'INICIO. Tratamiento del conteo de genes para la plataforma {platform}')\n",
    "# Expresión regular para filtrar los nombres de las columnas del csv generado por el script de R.\n",
    "re_GSM = re.compile('GSM[0-9]*_[0-9]*|GSM[0-9]*')\n",
    "\n",
    "#Series Descartadas\n",
    "seriesL = []\n",
    "for s in series.keys():\n",
    "    if s not in ['GSE52170','GSE60195','GSE60198','GSE72493','GSE82326','GSE89150','GSE89151',\n",
    "                 'GSE97865','GSE101086','GSE111859','GSE114537','GSE114540','GSE120352','GSE145686',\n",
    "                 'GSE181824']:\n",
    "        seriesL.append(s)\n",
    "        \n",
    "counts = pd.DataFrame(columns=seriesL,index=['counts','CPM','RPKM','TMP','TMM'])\n",
    "\n",
    "# Lectura de los archivos csv de todas las series.\n",
    "for serie in counts.keys():\n",
    "    path = f'{experiments_dir}/{serie}'\n",
    "    if os.path.isfile(f'{path}/gene_counts.csv'):\n",
    "        counts[serie]['counts'] = pd.read_csv(f'{path}/gene_counts.csv',index_col=0)\n",
    "        counts[serie]['counts'].columns = re_GSM.findall(\"\".join(counts[serie]['counts'].columns))\n",
    "        # Remplaza valores nulos con ceros.\n",
    "        counts[serie]['counts'].fillna(0,inplace=True)\n",
    "    else:\n",
    "        logger.error(f'No existe el archivo gene_counts.csv para la serie {serie}')\n",
    "logger.info('Lectura de archivos (gene_counts.csv) finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52959d",
   "metadata": {},
   "source": [
    "## Longitud de genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1dc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lectura del archivo de anotaciones del genoma (gtf).\n",
    "length_genes = read_gtf(genomaannot_gtffile)\n",
    "# Filtra solo los genes.\n",
    "length_genes = (length_genes[length_genes['feature']=='gene'])[['gene_id','start','end']]\n",
    "# Obtiene la longitud de los genes.\n",
    "length_genes['length'] = length_genes['end'] - length_genes['start']\n",
    "length_genes = length_genes.set_index('gene_id')['length']\n",
    "logger.info('Lectura de longitud de genes finalizado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab3988",
   "metadata": {},
   "source": [
    "# Normalizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ffc28",
   "metadata": {},
   "source": [
    "## Normalización CPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ba41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,serie in enumerate(counts.loc['counts'].dropna().keys()):\n",
    "    nmCPM = norm()\n",
    "    nmCPM.cpm(df = counts[serie]['counts'])\n",
    "    counts[serie]['CPM'] = nmCPM.cpm_norm\n",
    "logger.info('Normalización CPM finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36710c6",
   "metadata": {},
   "source": [
    "## Normalización RPKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    nmRPKM = norm()\n",
    "    nmRPKM.rpkm(df = counts[serie]['counts'].merge(length_genes,left_index=True,right_index=True),gl = 'length') \n",
    "    counts[serie]['RPKM'] = nmRPKM.rpkm_norm\n",
    "logger.info('Normalización RPKM finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251aa3f",
   "metadata": {},
   "source": [
    "## Normalización TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    nmTMP = norm()\n",
    "    nmTMP.tpm(df = counts[serie]['counts'].merge(length_genes,left_index=True,right_index=True),gl = 'length')\n",
    "    counts[serie]['TMP'] = nmTMP.tpm_norm\n",
    "logger.info('Normalización TMP finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52eead",
   "metadata": {},
   "source": [
    "## Normalización TMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "#  edgeR TMM normalization\n",
    "#--------------------------------------\n",
    "def edger_calcnormfactors(counts_df, ref=None, logratio_trim=0.3, sum_trim=0.05, acutoff=-1e10, verbose=False):\n",
    "    # Author: Francois Aguet\n",
    "    # https://github.com/broadinstitute/pyqtl/blob/master/qtl/norm.py\n",
    "    \"\"\"\n",
    "    Calculate TMM (Trimmed Mean of M values) normalization.\n",
    "    Reproduces edgeR::calcNormFactors.default\n",
    "    Scaling factors for the library sizes that minimize\n",
    "    the log-fold changes between the samples for most genes.\n",
    "    Effective library size: TMM scaling factor * library size\n",
    "    References:\n",
    "     [1] Robinson & Oshlack, 2010\n",
    "     [2] R functions:\n",
    "          edgeR::calcNormFactors.default\n",
    "          edgeR:::.calcFactorWeighted\n",
    "          edgeR:::.calcFactorQuantile\n",
    "    \"\"\"\n",
    "\n",
    "    # discard genes with all-zero counts\n",
    "    Y = counts_df.values.copy()\n",
    "    allzero = np.sum(Y>0,axis=1)==0\n",
    "    if np.any(allzero):\n",
    "        Y = Y[~allzero,:]\n",
    "\n",
    "    # select reference sample\n",
    "    if ref is None:  # reference sample index\n",
    "        f75 = np.percentile(Y/np.sum(Y,axis=0), 75, axis=0)\n",
    "        ref = np.argmin(np.abs(f75-np.mean(f75)))\n",
    "        if verbose:\n",
    "            print('Reference sample index: '+str(ref))\n",
    "\n",
    "    N = np.sum(Y, axis=0)  # total reads in each library\n",
    "\n",
    "    # with np.errstate(divide='ignore'):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        # log fold change; Mg in [1]\n",
    "        logR = np.log2((Y/N).T / (Y[:,ref]/N[ref])).T\n",
    "        # average log relative expression; Ag in [1]\n",
    "        absE = 0.5*(np.log2(Y/N).T + np.log2(Y[:,ref]/N[ref])).T\n",
    "        v = (N-Y)/N/Y\n",
    "        v = (v.T + v[:,ref]).T  # w in [1]\n",
    "\n",
    "    ns = Y.shape[1]\n",
    "    tmm = np.zeros(ns)\n",
    "    for i in range(ns):\n",
    "        fin = np.isfinite(logR[:,i]) & np.isfinite(absE[:,i]) & (absE[:,i] > acutoff)\n",
    "        n = np.sum(fin)\n",
    "\n",
    "        loL = np.floor(n*logratio_trim)+1\n",
    "        hiL = n + 1 - loL\n",
    "        loS = np.floor(n*sum_trim)+1\n",
    "        hiS = n + 1 - loS\n",
    "        rankR = stats.rankdata(logR[fin,i])\n",
    "        rankE = stats.rankdata(absE[fin,i])\n",
    "        keep = (rankR >= loL) & (rankR <= hiL) & (rankE >= loS) & (rankE <= hiS)\n",
    "        # in [1], w erroneously defined as 1/v ?\n",
    "        tmm[i] = 2**(np.nansum(logR[fin,i][keep]/v[fin,i][keep]) / np.nansum(1/v[fin,i][keep]))\n",
    "\n",
    "    tmm = tmm / np.exp(np.mean(np.log(tmm)))\n",
    "    return tmm\n",
    "\n",
    "\n",
    "def edger_cpm_default(counts_df, lib_size=None, log=False, prior_count=0.25):\n",
    "    \"\"\"\n",
    "    edgeR normalized counts\n",
    "    Reproduces edgeR::cpm.default\n",
    "    \"\"\"\n",
    "    if lib_size is None:\n",
    "        lib_size = counts_df.sum(axis=0)\n",
    "    if log:\n",
    "        prior_count_scaled = lib_size/np.mean(lib_size) * prior_count\n",
    "        lib_size <- lib_size + 2 * prior_count_scaled\n",
    "    lib_size = 1e-6 * lib_size\n",
    "    if log:\n",
    "        return np.log2((counts_df + prior_count_scaled)/lib.size)\n",
    "    else:\n",
    "        return counts_df / lib_size\n",
    "\n",
    "\n",
    "def edger_cpm(counts_df, tmm=None, normalized_lib_sizes=True):\n",
    "    \"\"\"\n",
    "    Return edgeR normalized/rescaled CPM (counts per million)\n",
    "    Reproduces edgeR::cpm.DGEList\n",
    "    \"\"\"\n",
    "    lib_size = counts_df.sum(axis=0)\n",
    "    if normalized_lib_sizes:\n",
    "        if tmm is None:\n",
    "            tmm = edger_calcnormfactors(counts_df)\n",
    "        lib_size = lib_size * tmm\n",
    "    return counts_df / lib_size * 1e6\n",
    "#--------------------------------------\n",
    "#  edgeR TMM normalization\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ce726",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serie in counts.loc['counts'].dropna().keys():\n",
    "    counts[serie]['TMM'] = edger_cpm(counts_df = counts[serie]['counts'])\n",
    "logger.info('Normalización TMM finalizada')\n",
    "logger.info(f'FIN. Tratamiento del conteo de genes para la plataforma {platform}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc12067",
   "metadata": {},
   "source": [
    "# Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxUpperWhisker( df ):\n",
    "    '''Obtener el valor maximo entre todos los brazos superiores de los boxplot generados por un data frame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor maximo entre todos los brazos superiores de los boxplot\n",
    "    '''\n",
    "    describe = df.astype('float32').describe()\n",
    "    return max(describe.loc['75%'] + (1.5*(describe.loc['75%'] - describe.loc['25%'])))\n",
    "def get_minLowerWhisker( df ):\n",
    "    '''Obtener el valor minimo entre todos los brazos inferirores de los boxplot de un data frame\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor minimo entre todos los brazos inferiores de los boxplot.\n",
    "    '''\n",
    "    describe = df.describe()\n",
    "    lowerWhisker = min(describe.loc['25%'] - (1.5*(describe.loc['75%'] - describe.loc['25%'])))\n",
    "    lowerVal = df.min().min()\n",
    "    return lowerWhisker if lowerVal < lowerWhisker else lowerVal\n",
    "\n",
    "def graficarBoxplot(df, title = 'Sin título', showfliers = False):\n",
    "    '''Gráfica los diagramas de caja y brazos de un data frame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con columnas-muestras, filas-genes, values-float32.\n",
    "    title : String\n",
    "        Título de la gráfica.\n",
    "    showfliers : Boolean\n",
    "        Indica si se quiere mostrar los valores atipicos de las diagrams de caja y brazos.\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Valor minimo entre todos los brazos inferiores de los boxplot.\n",
    "    '''\n",
    "    plot = df.boxplot(column = df.columns.to_list(), return_type = 'axes',showfliers = showfliers)\n",
    "    plot.set_ylim(get_minLowerWhisker(df),get_maxUpperWhisker(df))\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_title( title )\n",
    "    plot.tick_params(axis = 'y', colors = '0.9') # 0.9 light gray\n",
    "    plot.tick_params(axis = 'x', colors = 'none')\n",
    "    plot.title.set_color('0.9')\n",
    "    plot.xaxis.grid()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fe13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    logger.info('Visualización de boxplots')\n",
    "    if (counts.isna().sum().sum() > 0):\n",
    "        logger.warning(f'Las series {\", \".join([x for x in counts.columns if counts[x].isna().sum() > 0])} no tienen una grafica asignada.') \n",
    "    countSerie = [0, len(counts.dropna(axis=1).columns)]\n",
    "    for serie in counts.dropna(axis=1).columns:\n",
    "        countSerie[0] += 1\n",
    "        print(f'****** {serie} ****** [{countSerie[0]}/{countSerie[1]}]')\n",
    "        graficarBoxplot(counts[serie]['counts'], title=f'Conteo de genes {serie}')\n",
    "        graficarBoxplot(counts[serie]['CPM'], title=f'Normalización CPM {serie}')\n",
    "        graficarBoxplot(counts[serie]['RPKM'], title=f'Normalización RPKM {serie}')\n",
    "        graficarBoxplot(counts[serie]['TMP'], title=f'Normalización TMP {serie}')\n",
    "        graficarBoxplot(counts[serie]['TMM'], title=f'Normalización TMM {serie}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffb103",
   "metadata": {},
   "source": [
    "# Creación de documentos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc46b5",
   "metadata": {},
   "source": [
    "## Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354a694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info('INICIO. Creación de documentos')\n",
    "os.makedirs(documents_dir) if not os.path.exists(documents_dir) else None # Crea la carpeta si no existe\n",
    "os.chdir(documents_dir)\n",
    "logger.info(f'Cambio de directorio {documents_dir}')\n",
    "\n",
    "def get_bytesPdfBoxplotImage(serie, kind, boxpoints, df):\n",
    "    '''Crea un pdf en bytes con la imagen del diagrama de caja y brazos de un DataFrame.\n",
    "    Parameters\n",
    "    ----------\n",
    "    serie : String\n",
    "        Nombre de la serie (experimento).\n",
    "    kind : String\n",
    "        Tipo de datos (counts, CPM, RPKM, TMP, TMM).\n",
    "    boxpoints : Boolean\n",
    "        Indica si se quieren mostrar los valores atipicos de los diagramas de caja y brazos.\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con: columnas-muestras, filas-genes, values-float32.\n",
    "    Returns\n",
    "    -------\n",
    "    Bytes\n",
    "        Pdf en bytes de la imagen del boxplot.\n",
    "    '''\n",
    "    df = df.astype('float32')\n",
    "    title = f'Conteo de genes {serie}' if kind == 'counts' else f'Normalización {kind} {serie}'\n",
    "    fig = df.iplot(kind='box',boxpoints=boxpoints,title=title,yrange=[0,get_maxUpperWhisker(df)],asFigure=True) \n",
    "    fig.update_traces(marker_opacity = 0.5, selector=dict(type='box'))\n",
    "    fig.update_traces(marker_size = 2, selector=dict(type='box'))\n",
    "    fig.update_layout(showlegend = False)\n",
    "    fig.update_layout(font_size = 10)\n",
    "    fig.update_layout(width = (700 + len(df.columns)) if len(df.columns)>100 else 700)\n",
    "    fig.update_layout(height = 450)\n",
    "    return fig.to_image(format = 'pdf')\n",
    "\n",
    "def generatePdf(serie, boxpoints = False, df = counts):\n",
    "    '''Genera un archivo pdf con todas las gráficas de una serie\n",
    "    Parameters\n",
    "    ----------\n",
    "    serie : String\n",
    "        Nombre de la serie (experimento).\n",
    "    boxpoints : Boolean\n",
    "        Indica si se quieren mostrar los valores atipicos de los diagramas de caja y brazos.\n",
    "    df : DataFrame\n",
    "        Dataframe de pandas con: columnas-series, filas-kind(counts, CPM, RPKM, TMP, TMM), values-DataFrame.\n",
    "    Returns\n",
    "    -------\n",
    "    Void\n",
    "    '''\n",
    "    # Juntar los plotly en un pdf\n",
    "    merger = PdfFileMerger()\n",
    "    for kind in df.index:\n",
    "        merger.append(io.BytesIO(get_bytesPdfBoxplotImage(serie,kind,boxpoints,df[serie][kind])))\n",
    "    with open(f'{serie}.pdf','wb') as handle:\n",
    "        merger.write(handle) \n",
    "    logger.info(f'PDF generado correctamente: {serie}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622b0f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (counts.isna().sum().sum() > 0):\n",
    "    logger.warning(f'Las series {\", \".join([x for x in counts.columns if counts[x].isna().sum() > 0])} no tienen datos asignados.') \n",
    "countSerie = [0, len(counts.dropna(axis=1).columns)]\n",
    "for serie in counts.dropna(axis = 1).columns:\n",
    "    countSerie[0] += 1\n",
    "    logger.info(f'{serie}[{countSerie[0]}/{countSerie[1]}]')\n",
    "    generatePdf(serie,'outliers',counts)\n",
    "logger.info('Pdfs de boxplots generados correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c156af45",
   "metadata": {},
   "source": [
    "## Metadata de las series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b18c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(documents_dir) if not os.path.exists(documents_dir) else None # Crea la carpeta si no existe\n",
    "df_metadata = pd.DataFrame([],columns=['geo_accession','title','summary','status','submission_date','last_update_date','type','overall_design','contributor','contact_email','contact_institute','contact_laboratory','contact_country','platform_id','total_samples','num_samples_discarded','samples_discarded']) \n",
    "# Solo guarda las series que fueron procesadas\n",
    "for serie in counts.dropna(axis=1).columns:\n",
    "    newRow = {}\n",
    "    for title in [x for x in df_metadata.columns.to_list() if x not in ['total_samples','num_samples_discarded','samples_discarded']]:\n",
    "        try:\n",
    "            newRow[title] = ', '.join(series[serie].metadata[title]) if title != 'contributor' else ', '.join(list(map(lambda x: str(x).replace(',',' '),series[serie].metadata[title])))\n",
    "        except:\n",
    "            newRow[title] = None\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "    newRow[\"total_samples\"] = len(gsmsKeys)\n",
    "    newRow[\"num_samples_discarded\"] = None\n",
    "    newRow[\"samples_discarded\"] = None\n",
    "    newRow[\"platform_id\"] = platform\n",
    "\n",
    "    # Registro de muestras descartadas\n",
    "    discarded = [x for x in gsmsKeys if x not in counts[serie]['counts'].columns]\n",
    "    if len(discarded) == 0:\n",
    "        newRow[\"num_samples_discarded\"] = 0\n",
    "        newRow[\"samples_discarded\"] = 'No samples were discarded'\n",
    "    else:\n",
    "        newRow[\"num_samples_discarded\"] = len(discarded)\n",
    "        newRow[\"samples_discarded\"] = ', '.join(discarded)\n",
    "\n",
    "    df_metadata = df_metadata.append(newRow, ignore_index=True)\n",
    "    \n",
    "df_metadata.set_index('geo_accession',inplace=True)\n",
    "df_metadata.to_csv(f'{documents_dir}/experiments_data-{platform}.csv')\n",
    "logger.info(f'Metadata de series generado correctamente en: {documents_dir}/experiments_data-{platform}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c521a",
   "metadata": {},
   "source": [
    "## Metadata de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84684e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metadataSample = pd.DataFrame([],columns=['geo_accession','title','organism_ch1','status','submission_date','last_update_date','growth_protocol_ch1','molecule_ch1','extract_protocol_ch1','data_processing','data_processing','instrument_model','library_selection','library_source','library_strategy','platform_id']) \n",
    "# Solo guarda las series que fueron procesadas\n",
    "for serie in counts.dropna(axis=1).columns:\n",
    "    # Filtra las muestras para que sean solo de la plataforma elegida\n",
    "    gsmsKeys = [x for x in series[serie].gsms.keys() if series[serie].gsms[x].metadata['platform_id'][0]==platform]\n",
    "    # Registro de muestras descartadas\n",
    "    discarded = [x for x in gsmsKeys if x not in counts[serie]['counts'].columns]\n",
    "    for muestra in [x for x in gsmsKeys if x not in discarded]: # Si hay muestras descartadas no se añaden a este archivo\n",
    "        newRow = {}\n",
    "        for title in df_metadataSample.columns:\n",
    "            try:\n",
    "                newRow[title] = f'\\n'.join(series[serie].gsms[muestra].metadata[title])\n",
    "            except:\n",
    "                newRow[title] = None\n",
    "\n",
    "        df_metadataSample = df_metadataSample.append(newRow, ignore_index=True)\n",
    "    \n",
    "df_metadataSample.set_index('geo_accession',inplace=True)\n",
    "df_metadataSample.to_csv(f'{documents_dir}/samples_data-{platform}.csv')\n",
    "logger.info(f'Documento generado correctamente en: {documents_dir}/samples_data-{platform}.csv')\n",
    "logger.info('FIN. Creación de documentos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b698774",
   "metadata": {},
   "source": [
    "# Creación de la matriz de muestras con correción de Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Corrección de Batch 1\n",
    "'''\n",
    "\n",
    "logger.info('INICIO. Creación de matrices de las muestras')\n",
    "genes_id = read_gtf(genomaannot_gtffile) \n",
    "genes_id = genes_id[genes_id['feature']=='gene'].reset_index()['gene_id']\n",
    "logger.info(f'Lectura de genes del archivo {genomaannot_gtffile} finalizado')\n",
    "\n",
    "samples = pd.DataFrame(columns=['beforeBatchN','afterBatchN'],index=['CPM','RPKM','TMP','TMM'])\n",
    "\n",
    "for kind in samples.index:\n",
    "    logger.info(f'Inicio. Normalización de batch a {kind}')\n",
    "    batchVector = []\n",
    "    temp = pd.DataFrame(index=genes_id)\n",
    "    for index,serie in enumerate(counts.dropna(axis = 1).columns):\n",
    "        temp = temp.merge(counts[serie][kind],left_index=True,right_index=True,how='left').fillna(0)\n",
    "        batchVector += [index for x in range(len(counts[serie][kind].columns))] \n",
    "        \n",
    "    #### REMOVER LOS GENES QUE TENGAN VARIANZA IGUAL A CERO\n",
    "    drpgen = pd.DataFrame([],columns = temp.columns)\n",
    "    for gen in temp.index:\n",
    "        if temp.loc[gen].var() == 0:\n",
    "            drpgen = drpgen.append(temp.loc[gen])\n",
    "            temp = temp.drop([gen],axis=0)\n",
    "    logger.info(f'{len(drpgen.index)} genes tienen varianza igual a cero')\n",
    "    \n",
    "    samples['beforeBatchN'][kind] = temp.append(drpgen).astype('float32')\n",
    "    \n",
    "    # Normalizacion de batch\n",
    "    try:\n",
    "        # Se especifica una correción NO paramétrica, si se desea lo contrario eliminar el parametro par_prior = False \n",
    "        samples['afterBatchN'][kind] = pycombat(temp.astype('float32'),batchVector, par_prior = False).append(drpgen).astype('float32')\n",
    "        logger.info(f'Normalización de Batch aplicada correctamente a {kind}')\n",
    "    except:\n",
    "        samples['afterBatchN'][kind] = np.NaN\n",
    "        logger.error(f'Ocurrio un problema en la normalización de batch de {kind}')\n",
    "\n",
    "logger.info('FIN. Creación de matrices de las muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fcafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Corrección de Batch 2 (con aplicación de log2) \n",
    "'''\n",
    "\n",
    "logger.info('INICIO. Creación de matrices de las muestras')\n",
    "genes_id = read_gtf(genomaannot_gtffile) \n",
    "genes_id = genes_id[genes_id['feature']=='gene'].reset_index()['gene_id']\n",
    "logger.info(f'Lectura de genes del archivo {genomaannot_gtffile} finalizado')\n",
    "\n",
    "samples = pd.DataFrame(columns=['beforeBatchN','afterBatchN'],index=['CPM','RPKM','TMP','TMM'])\n",
    "\n",
    "for kind in samples.index:\n",
    "    logger.info(f'Inicio. Normalización de batch a {kind}')\n",
    "    batchVector = []\n",
    "    temp = pd.DataFrame(index=genes_id)\n",
    "    for index,serie in enumerate(counts.dropna(axis = 1).columns):\n",
    "        temp = temp.merge(counts[serie][kind],left_index=True,right_index=True,how='left').fillna(0)\n",
    "        batchVector += [index for x in range(len(counts[serie][kind].columns))] \n",
    "        \n",
    "    #### REMOVER LOS GENES QUE TENGAN VARIANZA IGUAL A CERO\n",
    "    drpgen = pd.DataFrame([],columns = temp.columns)\n",
    "    for gen in temp.index:\n",
    "        if temp.loc[gen].var() == 0:\n",
    "            drpgen = drpgen.append(temp.loc[gen])\n",
    "            temp = temp.drop([gen],axis=0)\n",
    "    logger.info(f'{len(drpgen.index)} genes tienen varianza igual a cero')\n",
    "    \n",
    "    samples['beforeBatchN'][kind] = temp.append(drpgen).astype('float32')\n",
    "    \n",
    "    # log2 para homogenizar de valores\n",
    "    df_log = pd.DataFrame(np.log2(temp), index=temp.index, columns=temp.columns).replace(np.NINF,0)\n",
    "    \n",
    "    # Volviendo ceros los valores negativos en caso de haberlos \n",
    "    for c in df_log:\n",
    "        df_log.loc[df_log[c]<0,c] = 0\n",
    "    \n",
    "    # Normalizacion de batch no paramétrica\n",
    "    try:\n",
    "        # Se especifica una correción paramétrica, si se desea lo contrario agregar el parametro par_prior = False después de batchVector\n",
    "        samples['afterBatchN'][kind] = pycombat(df_log.astype('float32'),batchVector).append(drpgen).astype('float32')\n",
    "        logger.info(f'Normalización de Batch aplicada correctamente a {kind}')\n",
    "    except:\n",
    "        samples['afterBatchN'][kind] = np.NaN\n",
    "        logger.error(f'Ocurrio un problema en la normalización de batch de {kind}')\n",
    "\n",
    "logger.info('FIN. Creación de matrices de las muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ed8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if showGraphs:\n",
    "    logger.info('Visualización de boxplots')\n",
    "    plt.rcParams[\"figure.figsize\"] = (30,15)\n",
    "    for y in samples.index:\n",
    "        for x in samples.columns:\n",
    "            print(f'{x} tipo {y}')\n",
    "            graficarBoxplot(samples[x][y],title=f'{x} tipo {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera archivos csv para cada uno de las matrices (CPM, RPKM, TMP, TMM) a las que se le aplico correctamente el ajuste de batch \n",
    "for kind in samples.dropna(axis = 0).index:\n",
    "    samples['afterBatchN'][kind].to_csv(f'{documents_dir}/matrizAfterBatch{kind}.csv')\n",
    "    logger.info(f'Matriz guardada en: {documents_dir}/matrizAfterBatch{kind}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
